# Titanic-Survival-Prediction-Model
In this exploration of the renowned Titanic Disaster Dataset, our central focus is the utilization of advanced Machine Learning algorithms to predict passenger survival. This undertaking stands out as a noteworthy challenge on the Kaggle platform, known for its competitive data science community. The primary objective of this repository is to serve as an instructive tutorial, strategically crafted for individuals who are novices in the Kaggle environment. The content of the notebook has been meticulously curated with a deliberate emphasis on simplicity. Each aspect is systematically addressed, employing an approach tailored to beginners, thereby ensuring that the material is easily comprehensible for those embarking on their journey into the expansive field of Machine Learning.

Delving into the illustrious Titanic Disaster Dataset through the application of Machine Learning algorithms, our primary objective is to forecast passenger survival. This endeavor distinguishes itself as a prominent challenge within the Kaggle platform. The primary goal of this repository is to function as a tutorial, specifically tailored for novices entering the realm of Kaggle. Meticulously crafted with a focus on simplicity, this notebook systematically addresses each facet with an approach conducive to beginners, ensuring accessibility for those initiating their journey into the realm of Machine Learning.

The application of intricate algorithms, coupled with the systematic exploration of the dataset, underscores the sophisticated nature of the project. By emphasizing accessibility, the tutorial is designed to empower newcomers with the foundational knowledge necessary to navigate Kaggle competitions and embark on their Machine Learning journey with confidence. This comprehensive approach aims to demystify the intricacies of data science, making it an engaging and educational experience for individuals at the onset of their analytical expedition.

# Dependencies:
- Python3
- Numpy
- Pandas
- Matplotlib
- Supervised Learning
- Machine Learning Algorithm
- Classification Algorithms

# This Notebook will show basic examples of:
- Data Handling
- Importing Data with Pandas
- Cleaning Data
- Exploring Data through Visualizations with Matplotlib

# Data Analysis:
Supervised Machine Learning Techniques used:
- Decision Tree Regression
- Logistic Regression
- Support Vector Machines
- Gaussian Naive Bayes

## Overview

The sinking of the Titanic is a tragic event in history, and this project aims to analyze and predict the factors that influenced survival. The main focus is on building a robust predictive model using Python, leveraging popular machine learning libraries.

## Features

- **Data Exploration:** Dive into the dataset to understand the characteristics of the passengers, their demographics, and the distribution of survival outcomes.

- **Preprocessing:** Cleanse and preprocess the data to handle missing values, outliers, and ensure it is suitable for training machine learning models.

- **Feature Engineering:** Extract valuable insights from the dataset by creating new features and transforming existing ones to enhance the model's predictive power.

- **Machine Learning Models:** Implement various machine learning algorithms, such as decision trees, random forests, and logistic regression, to predict survival outcomes.

- **Evaluation:** Assess the performance of the models using metrics like accuracy, precision, recall, and F1-score to ensure the reliability of predictions.

## Getting Started

1. Clone the repository to your local machine.
   ```bash
   git clone https://github.com/DorzahThapelo/Titanic-Survival-Prediction-Model.git
   ```

2. Install the required dependencies.
   ```bash
   pip install -r requirements.txt
   ```

3. Explore the Jupyter notebooks in the `notebooks` directory to understand the step-by-step process of building the Titanic Survival Prediction Model.

4. Run the provided Python scripts for data preprocessing, model training, and evaluation.

## Contributing

Feel free to contribute to the project by opening issues, suggesting improvements, or submitting pull requests. Your input is valuable, and together we can enhance the accuracy and scope of the predictive model.

Happy coding and may the odds be ever in your favor!

## CONCLUSION
The best models are Logistic Regression with an accuracy of 91% and the Gaussian Naive Bayes Model with an accuracy od 90%.

